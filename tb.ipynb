{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparam_keys ['remark', 'lr_decay', 'arch', 'step', 'loss', 'lr']\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,loss=ce,lr=0.01,lr_decay=linear,remark=resume_linear_2020-10-17_16-50-33zggi5r64/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,loss=ce,lr=0.05,lr_decay=linear,remark=resume_linear_2020-10-17_13-23-20o7esys9e/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,loss=ce,lr=0.05,lr_decay=linear_2020-10-16_20-51-487e84em1z/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,loss=focalloss,lr=0.001,lr_decay=cos,remark=resume_step5_2020-10-16_15-06-184vrdo720/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,loss=focalloss,lr=0.01,lr_decay=cos_2020-10-16_10-49-54mn5i5pdz/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,loss=focalloss,lr=0.1,lr_decay=cos_2020-10-16_12-44-17l49bf821/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,lr=0.01,lr_decay=cos_2020-10-16_00-35-57ola4ylls/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,lr_decay=cos_2020-10-15_16-35-0393pgwkma/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50,step=5_2020-10-15_09-47-38bnvxfefr/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnet50_2020-10-14_21-57-31cbu51_hn/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d,loss=ce,lr=0.01,lr_decay=linear_2020-10-17_22-58-28k0imsqzg/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d,loss=ce,lr=0.01,lr_decay=linear_2020-10-18_11-02-09eo90q_qz/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d,loss=ce,lr=0.01,lr_decay=linear_2020-10-18_13-18-21p9k71gct/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d,loss=focalloss,lr=0.005,lr_decay=linear_2020-10-18_20-40-017i_zjvsf/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d,loss=focalloss,lr=0.01,lr_decay=linear_2020-10-18_16-42-07lo4gzlfq/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d_2020-10-14_00-36-375l2q0kye/progress.csv\n",
      "csv:  ray_results/run_report/main_0_arch=resnext50_32x4d_2020-10-14_13-49-06xqtbgq2v/progress.csv\n",
      "csv:  ray_results/run_report/main_1_arch=resnet50_2020-10-14_03-50-03tvwvwcek/progress.csv\n"
     ]
    }
   ],
   "source": [
    "# read the experirements, loop one to scan all hyperparameter values\n",
    "# params.json store the config (hyperpara)\n",
    "# progress.csv contain metric for every ep\n",
    "def gen_tb_report_from_ray(ray_exp_root_folder:str, output_folder: str, metrics_key_list: list, hparam_default_dict: dict = {}):\n",
    "    \n",
    "    ########## 1. Find out all Possible Hyper Parameter Keys ##########\n",
    "    hparam_keys = []\n",
    "    exps_folder = []\n",
    "\n",
    "    for filename in os.listdir(ray_exp_root_folder):\n",
    "        exp_folder = f\"{ray_exp_root_folder}/{filename}\"\n",
    "        if filename.startswith(\".\") or os.path.isfile(exp_folder):\n",
    "            continue\n",
    "\n",
    "        exps_folder.append(exp_folder)\n",
    "        params_fp = f\"{exp_folder}/params.json\"\n",
    "        with open(params_fp) as json_file:\n",
    "            params = json.load(json_file)\n",
    "            hparam_keys = list(set(hparam_keys + list(params.keys())))\n",
    "\n",
    "    print(\"hparam_keys\", hparam_keys)\n",
    "    ########## End 1. Find out all Possible Hyper Parameter Keys ##########\n",
    "\n",
    "\n",
    "    ########## 2. Write To TensorBoard Scaler, Hparam ##########\n",
    "    # ref: https://pytorch.org/docs/stable/tensorboard.html\n",
    "    # for each experiments\n",
    "    for e, exp_folder in enumerate(exps_folder):\n",
    "        exp_name = f\"exp_{e}\"\n",
    "        params_fp = f\"{exp_folder}/params.json\"\n",
    "        with open(params_fp) as json_file:\n",
    "            params = json.load(json_file)\n",
    "            for k, v in params.items():\n",
    "                exp_name += f\"_{k}={v}\"\n",
    "\n",
    "        w = SummaryWriter(log_dir=f\"{output_folder}/{exp_name}\")\n",
    "        ######### Scalars Report #########\n",
    "        csv_fp = f\"{exp_folder}/progress.csv\"\n",
    "        if os.path.getsize(csv_fp) == 0:\n",
    "            print(\"Empty file, skip it\")\n",
    "            continue\n",
    "        df = pd.read_csv(csv_fp)\n",
    "        for i, row in df.iterrows():\n",
    "            for k in metrics_key_list:\n",
    "                if k in df:\n",
    "                    w.add_scalar(f\"metrics/{k}\",row[k], i)\n",
    "        ######### End Scalars Report #########\n",
    "\n",
    "\n",
    "        ######### Hyper Parameter Report #########\n",
    "        #### Build the Hparam Dict\n",
    "        hparam_dict = {}\n",
    "        for k in hparam_keys:\n",
    "            default = \"\"\n",
    "            if k in hparam_default_dict:\n",
    "                default = hparam_default_dict[k]\n",
    "\n",
    "            params_fp = f\"{exp_folder}/params.json\"\n",
    "            with open(params_fp) as json_file:\n",
    "                params = json.load(json_file)\n",
    "\n",
    "                hparam_dict[k] = default if k not in params else params[k]\n",
    "\n",
    "        # read the best matric\n",
    "        csv_fp = f\"{exp_folder}/progress.csv\"\n",
    "        print(\"csv: \", csv_fp)\n",
    "        df = pd.read_csv(csv_fp)\n",
    "        best_it = df.iloc[df['prec1'].argmax()]\n",
    "\n",
    "        metric_dict = {}\n",
    "        for k in metrics_key_list:\n",
    "            if k in df:\n",
    "                metric_dict[f\"best/{k}\"] = best_it[k]\n",
    "        w.add_hparams(hparam_dict, metric_dict)\n",
    "        ######### End of Hyper Parameter Report #########\n",
    "        w.close()\n",
    "    ########## 2. Write To TensorBoard Scaler, Hparam ##########\n",
    "    \n",
    "ray_exp_root_folder = \"ray_results/run_report\"\n",
    "metrics_key_list = [\"lr\", \"prec1\", \"train_loss\", \"val_loss\"]\n",
    "hparam_default_dict = {\"arch\": \"\", \n",
    "                       \"remark\": \"\", \n",
    "                       \"loss\": \"ce\", \n",
    "                       \"lr_decay\": \"step\", \n",
    "                       \"step\": -1, \n",
    "                       \"lr\": -1}\n",
    "gen_tb_report_from_ray(ray_exp_root_folder, \"test_tb\", metrics_key_list, hparam_default_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
